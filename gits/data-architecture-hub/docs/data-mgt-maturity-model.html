<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="generator" content="pandoc">
    <meta name="description" content="">
    <meta name="author" content="Data Management Team">

    <title>AXA DATA ARCHITECTURE HUB</title>

    <!-- Bootstrap core CSS -->	
	<!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous"> -->
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">

    <!-- Custom styles for this template -->
    <link href="https://mushiyo.github.io/pandoc-toc-sidebar/css/dashboard.css" rel="stylesheet">
	
	<!-- Font Awesome icons, cf. https://fontawesome.com/v4/icons/ -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <!-- light/dark mode -->
    <style type="text/css">	
		:root {--background-color: white; --caption-color: 'white'; --text-color: black; --content-color: #1C242B; --border-color: #ECECEC;}
		
		body {background: var(--background-color); var(--text-color);}
		i {background: var(--background-color); var(--text-color);}
		.caption {background: var(--caption-color); color: var(--text-color); padding: 10px 20px 20px 10px;}
		.sidebar {background: var(--background-color); color: var(--text-color);}
		.head {color: var(--text-color);}
		table {border: 1px solid var(--border-color);}
		th {border-top: 1px solid var(--border-color); border-bottom: 1px solid var(--border-color); border-left: none; border-right: none; color: var(--text-color);}
		tr {border-top: 1px solid var(--border-color); border-bottom: 1px solid var(--border-color); border-left: none; border-right: none; color: var(--text-color);}
		td {border-top: 1px solid var(--border-color); border-bottom: 1px solid var(--border-color); border-left: none; border-right: none; color: var(--text-color);}
		code {white-space: pre;}
		h1 {color: var(--content-color);}
		h2 {color: var(--content-color);}
		h3 {color: var(--content-color);}
		h4 {color: var(--content-color);}
		p {color: var(--content-color);}
		li {color: var(--content-color);}
		summary {color: var(--content-color);}
		.navbar {width: 100%; margin-left: auto; margin-right: auto; border: solid 2px;}
	</style>
	
	<style type="text/css">.mainleft{padding-left: 18%;}</style>
  </head>

  <body>
  <!--
  -->

<!-- CUSTOMIZATION BEGIN [we integrate nav banner directly here otherwise variables are not resolved -->
<!-- cf. https://github.com/ashki23/pandoc-bootstrap -->
<!--<nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">&nbsp;&nbsp;-->
<nav class="navbar fixed-top navbar-dark bg-dark">
<div style=" display: flex; float: left;">&nbsp;&nbsp;
<a class="navbar-brand" href="index.html"><b>AXA DATA ARCHITECTURE HUB</b> - DATA MATURITY MODEL </a>
</div>

<div style=" display: flex; float: right;">
        <!--<button id="switch" onclick="toggleTheme()">Switch</button>-->
<a class="btn btn-secondary d-block" data-toggle="collapse" onclick="setTheme('theme-light');" role="button" title="Light Mode">
<span class="fa fa-sun-o"/>
</a>&nbsp;
<a class="btn btn-secondary d-block" data-toggle="collapse" onclick="setTheme('theme-dark');" role="button" title="Dark Mode">
<span class="fa fa-moon-o"/>
</a>&nbsp;
      </div>

</nav>
<!-- CUSTOMIZATION END -->

    <div class="container-fluid">
	     <div class="row">
        <div id="sidebar" class="col-sm-3 col-md-2 sidebar">
          <ul>
          <li><a href="#identify-and-deliver-value-through-use-cases-systematically-at-scale">1. Identify and Deliver Value Through Use Cases – Systematically, at Scale</a></li>
          <li><a href="#ensure-appropriate-use-and-protection-of-data-in-a-risk-based-approach">2. Ensure appropriate use and protection of data, in a risk based approach</a></li>
          <li><a href="#govern-the-data-strategy-and-data-driven-transformation-holistically">3. Govern the Data Strategy and Data-Driven Transformation – Holistically</a></li>
          <li><a href="#manage-data-as-an-asset">4. Manage data as an asset</a></li>
          <li><a href="#empower-people-and-the-broader-organization-to-deliver">5. Empower People, and the broader Organization, to Deliver</a></li>
          <li><a href="#deliver-and-operate-data-platforms">6. Deliver and operate data platforms</a></li>
          </ul>
        </div>
        <div class="col-sm-9 col-sm-offset-3 col-md-10 col-md-offset-2 mainleft">
<br/>
<p><a href="media/data-mgt/2022_DMA_Template_1.0.xlsx">2020-DMA_template_1.2</a></p>
<h3 id="identify-and-deliver-value-through-use-cases-systematically-at-scale">1. Identify and Deliver Value Through Use Cases – Systematically, at Scale</h3>
<div class="row">
<table width="100%">
<thead>
<tr>
<th width="25%">
Dimension/sections
</th>
<th width="15%">
L1 - No/Does not exist
</th>
<th width="15%">
L2 - Initial
</th>
<th width="15%">
L3 - Ad hoc
</th>
<th width="15%">
L4 - Managed
</th>
<th width="15%">
L5 - Institutionalized
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">
1.1. USE CASE IDEATION AND PORTFOLIO
</td>
</tr>
<tr>
<td>
How and to what extent do you manage your data-driven use case portfolio?
</td>
<td>
No system in place or no use cases are under execution
</td>
<td>
Ad’hoc data driven use case based on requests by the business, funding ad’hoc (“spontaneous coalitions of stakeholders lead to use case prioritization and execution”)
</td>
<td>
Data driven use case portfolio management with active opportunity identification and prioritization mechanism in place, regular review/pitch with the business for new use cases and allocation of funding
</td>
<td>
Entity has transparency on major value areas for data analytics, portfolio management system in place with specific criteria for use case validation and selection; for each use case, economic potential or strategic intent is understood; funding mechanism in place to deal adequately with individual use cases’ uncertainty
</td>
<td>
Potential and feasibility of data analytics well understood by data-affine community across the entity; active contribution by the community in driving use cases from ideation to execution
</td>
</tr>
<tr>
<td>
To what extent data-driven use cases drive existing business profits and growth?
</td>
<td>
No use cases are executed yet but some ideas are identified
</td>
<td>
Some use cases are under execution based on opportunities identified with the business, first learnings generated
</td>
<td>
Use cases prioritized and executed based on an impact/potential vs. feasibility (or similar) evaluation approach, first validated impact(s) generated
</td>
<td>
Use case evaluation and priorization framework established (criteria such as e.g., economic levers, IT and business change feasibility, analytical modeling feasibility, required data availability) and hurdles to impact are identified and addressed
</td>
<td>
Data analytics, business and IT teams follow a joint long-term plan to maximize impact from data, particularly by removing or overcoming hurdles
</td>
</tr>
<tr>
<td>
To what extent are exploratory initiatives (i.e. without an immediate ROI goal) in place to test new methods and foster innovation?
</td>
<td>
No initiatives are executed yet but some ideas are identified
</td>
<td>
Some ideas have been identified and small tests took place, first learnings generated
</td>
<td>
The initiatives have been prioritized by systematic approach and a few of them are under execution
</td>
<td>
A funnel of initiatives, with well-understood strategic intent (but no immediate ROI requirements), in place to generate valuable learnings for future business opportunities
</td>
<td>
Some of the launched initiatives are already disrupting the market; continuous testing, capability building, and development of new business models with upcoming initiatives
</td>
</tr>
<tr>
<td colspan="6">
1.2. MEASURING SUCCESS OF USE CASES
</td>
</tr>
<tr>
<td>
How do you measure the impact of data-driven use cases?
</td>
<td>
No measurement of impact availble yet
</td>
<td>
Ad-hoc observations and estimates of use case benefits are available
</td>
<td>
There is at least an estimate of annualized impact (e.g. pretax-UE or GWP or APE …) available for each use case for which it can be measured or estimated in some way
</td>
<td>
There is an established framework and guidelines in place which are applied to all use cases, which defines measures and the way to calculate them; where feasible, A/B tests are employed to measure realized impact
</td>
<td>
There is a wider awareness of business stakeholders of the framework/guidelines and how it is measured
</td>
</tr>
<tr>
<td>
To what extent are impact measurements established and aligned with entity stakeholders?
</td>
<td>
No measurement of impact performed yet
</td>
<td>
Estimates of use case benefits are generated and communicated ad’hoc, (e.g. when they become available from the project team that delivered the use case)
</td>
<td>
Impact estimation is an established activity; results are aligned with stakeholders involving at least the business PnL owner of the use case
</td>
<td>
A framework/guideline of impact measurement is regularly applied, with involvement of key ExCom stakeholders including Finance, to perform regular alignments of measurements
</td>
<td>
Beyond direct stakeholders, measurement methods are more widely used and applied in the organization (e.g. for digital/UX cases)
</td>
</tr>
<tr>
<td colspan="6">
1.3. MANAGE ANALYTICAL MODELS
</td>
</tr>
<tr>
<td>
To what extent are analytical models managed?
</td>
<td>
Not managed
</td>
<td>
Analytical Models are thoroughly backtested before deployment
</td>
<td>
Regular monitoring of Analytical Models performance while in production
</td>
<td>
Procedure for model retraining/switch is operationalized for all the analytical models (beyond pricing)
</td>
<td>
Analytical Models are deployed and analysed in continuous manner
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="ensure-appropriate-use-and-protection-of-data-in-a-risk-based-approach">2. Ensure appropriate use and protection of data, in a risk based approach</h3>
<div class="row">
<table>
<thead>
<tr>
<th width="25%">
Dimension/sections
</th>
<th width="15%">
L1 - No/Does not exist
</th>
<th width="15%">
L2 - Initial
</th>
<th width="15%">
L3 - Ad hoc
</th>
<th width="15%">
L4 - Managed
</th>
<th width="15%">
L5 - Institutionalized
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">
2.1. COMPLY TO DATA PRIVACY AND PROTECTION LAWS
</td>
</tr>
<tr>
<td>
To what extend is the entity aligned with AXA’s data privacy standards?
</td>
<td>
Actions haven’t started yet - do not have yet a Data Privacy Maturity Assessment score
</td>
<td>
Not aligned yet but a plan to reach the standard in the future - (score 50-75% on Data Privacy Maturity Assessment
</td>
<td>
Not yet fully aligned but confident to reach the standard in the near future - (score 75%+on Data Privacy Maturity Assessment (DPMA)
</td>
<td>
Fully aligned with AXA Standards (score 100% on Data Privacy Maturity Assessment
</td>
<td>
Processes and tools are beyond AXA standards - advanced level in Data Privacy Maturity Assessment
</td>
</tr>
<tr>
<td colspan="6">
2.2. IMPLEMENT INFORMATION SECURITY STANDARDS
</td>
</tr>
<tr>
<td>
To what extend is the entity aligned with ISO27000 Standards (as part of AXA’s information security standards)?
</td>
<td>
Actions haven’t started yet - do not have yet performed ISO27000 Assessment
</td>
<td>
Score 1- &lt; 2
</td>
<td>
Score 2- &lt; 3
</td>
<td>
Score 3 achieved, or above
</td>
<td>
Score 4 - 5
</td>
</tr>
<tr>
<td colspan="6">
2.3. ETHICAL USE OF DATA
</td>
</tr>
<tr>
<td>
To what extend is the Ethical usage of data enforced in the entity?
</td>
<td>
This has not been considered
</td>
<td>
A point of view is emerging, initial ideas have been discussed and drafted
</td>
<td>
AXA employees facing ethical concerns pertaining to the usage of data can ask for guidance, and receive it in a timely manner
</td>
<td>
Entity pro-actively provides guidance on Data Ethics to employees and customers, and ensures data products and algorithms are deployed in an ethical way
</td>
<td>
Entity is recognized as a market leader in this field
</td>
</tr>
<tr>
<td colspan="6">
2.5. DATA MANAGEMENT INTERNAL CONTROL
</td>
</tr>
<tr>
<td>
Have you implemented Data Management Internal Control process?
</td>
<td>
No process in place (ad-hoc controls)
</td>
<td>
Process is defined but not implemented or not completed on the whole scope of controls
</td>
<td>
Process is defined and implemented, controls are regularly done
</td>
<td>
The results of these controls are reviewed and validated by the second line of defense
</td>
<td>
Results of reviewed controls are used to improve data management processes in BAU
</td>
</tr>
<tr>
<td colspan="6">
2.6. DIGITAL SUSTAINABILITY
</td>
</tr>
<tr>
<td>
As part of broader Digital Sustainability strategy led by CIO, to what extent, as a CDO, do you contribute to the management of the volume of data – at rest / in motion in your entity throughout the data lifecycle (from creation to deletion)?
</td>
<td>
The volume of structured / unstructured data is measured on a limited scope
</td>
<td>
The volume of structured / unstructured data is regularly measured and some ad hoc actions are performed to stabilise or even reduce the volume of data
</td>
<td>
Managing data volumes is part of the Data Strategy. Data minimization processes are in place beyond personal data to minimize big volumes of data at rest or in motion, including deletion
</td>
<td>
L4 on a full scope
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="govern-the-data-strategy-and-data-driven-transformation-holistically">3. Govern the Data Strategy and Data-Driven Transformation – Holistically</h3>
<div class="row">
<table>
<thead>
<tr>
<th width="25%">
Dimension/sections
</th>
<th width="15%">
L1 - No/Does not exist
</th>
<th width="15%">
L2 - Initial
</th>
<th width="15%">
L3 - Ad hoc
</th>
<th width="15%">
L4 - Managed
</th>
<th width="15%">
L5 - Institutionalized
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">
3.1. DEFINE AND ESTABLISH A DATA STRATEGY
</td>
</tr>
<tr>
<td>
To what extent is your Data Strategy developed and established in your entity?
</td>
<td>
Some ad’hoc activities without a written plan
</td>
<td>
Draft version with a first perspective on use cases and associated capabilities in discussion with senior business stakeholders
</td>
<td>
Strategy and associated budget validated by the ExCom containing prioritized use cases, a plan for required capabilities, and a perspective on expected impact and learnings
</td>
<td>
Strategy and roadmap regularly reviewed with ExCom, balancing impact creation from use cases and investments in capabilities, with appropriate short- and long-term funding
</td>
<td>
L4 + strategy and roadmap address all major value areas and innovations as well as foundations; strategy understood and actively supported by community of data-affine managers and staff across the entity
</td>
</tr>
<tr>
<td colspan="6">
3.2. EMPOWER CDO, DATA TEAM, AND STAKEHOLDERS TO JOINTLY DELIVER THE DATA STRATEGY
</td>
</tr>
<tr>
<td>
What is the position of the CDO vis-à-vis the local ExCom?
</td>
<td>
No CDO appointed in the entity
</td>
<td>
Not full time, but someone officially acting as CDO is an indirect report to ExCom member
</td>
<td>
Full time, appointed CDO is an indirect report to ExCom member
</td>
<td>
Full time CDO is a direct report to ExCom member
</td>
<td>
CDO is member of the ExCom
</td>
</tr>
<tr>
<td>
To what extent are the CDO and the core data team empowered on the DATA STRATEGY DEFINITION &amp; EXECUTION activities of the CDO job description? <i>(and in case it is not the CDO and/or core data team, please add in comments who else in the organization is empowered to deliver this part)</i>
</td>
<td>
Planned to take into account in the next 12 months or more
</td>
<td>
Some scattered actions are being performed without a clear roadmap
</td>
<td>
Activities are performed following a plan - invited to present and validate this domain to local ExCom twice a year
</td>
<td>
Performing activities with a defined and validated roadmap - regular follow up session on this specific domain with ExCom (could also be covered via Databoard, see 3.3 below)
</td>
<td>
4+ Outperforming activities, recognized by its peers and the industry as best practice leader in this domain
</td>
</tr>
<tr>
<td>
To what extent are the CDO and the core data team empowered on the DATA MANAGEMENT activities of the CDO job description? <i>(and in case it is not the CDO and/or core data team, please add in comments who else in the organization is empowered to deliver this part)</i>
</td>
<td>
Planned to take into account in the next 12 months or more
</td>
<td>
Some scattered actions are being performed without a clear roadmap
</td>
<td>
Activities are performed following a plan - invited to present and validate this domain to local ExCom twice a year
</td>
<td>
Performing activities with a defined and validated roadmap - regular follow up session on this specific domain with ExCom (could also be covered via Databoard, see 3.3 below)
</td>
<td>
4+ Outperforming activities, recognized by its peers and the industry as best practice leader in this domain
</td>
</tr>
<tr>
<td>
To what extent are the CDO and the core data team empowered on the DATA PROTECTION activities of the CDO job description? <i>(and in case it is not the CDO and/or core data team, please add in comments who else in the organization is empowered to deliver this part)</i>
</td>
<td>
Planned to take into account in the next 12 months or more
</td>
<td>
Some scattered actions are being performed without a clear roadmap
</td>
<td>
Activities are performed following a plan - invited to present and validate this domain to local ExCom twice a year
</td>
<td>
Performing activities with a defined and validated roadmap - regular follow up session on this specific domain with ExCom (could also be covered via Databoard, see 3.3 below)
</td>
<td>
4+ Outperforming activities, recognized by its peers and the industry as best practice leader in this domain
</td>
</tr>
<tr>
<td>
To what extent are the CDO and the core data team empowered on the MANAGEMENT OF RISK activities of the CDO job description? <i>(and in case it is not the CDO and/or core data team, please add in comments who else in the organization is empowered to deliver this part)</i>
</td>
<td>
Planned to take into account in the next 12 months or more
</td>
<td>
Some scattered actions are being performed without a clear roadmap
</td>
<td>
Activities are performed following a plan - invited to present and validate this domain to local ExCom twice a year
</td>
<td>
Performing activities with a defined and validated roadmap - regular follow up session on this specific domain with ExCom (could also be covered via Databoard, see 3.3 below)
</td>
<td>
4+ Outperforming activities, recognized by its peers and the industry as best practice leader in this domain
</td>
</tr>
<tr>
<td>
To what extent are the CDO and the core data team empowered on the MANAGEMENT OF CHANGE activities of the CDO job description? <i>(and in case it is not the CDO and/or core data team, please add in comments who else in the organization is empowered to deliver this part)</i>
</td>
<td>
Planned to take into account in the next 12 months or more
</td>
<td>
Some scattered actions are being performed without a clear roadmap
</td>
<td>
Activities are performed following a plan - invited to present and validate this domain to local ExCom twice a year
</td>
<td>
Performing activities with a defined and validated roadmap - regular follow up session on this specific domain with ExCom (could also be covered via Databoard, see 3.3 below)
</td>
<td>
4+ Outperforming activities, recognized by its peers and the industry as best practice leader in this domain
</td>
</tr>
<tr>
<td colspan="6">
3.3. RUN A DATA BOARD
</td>
</tr>
<tr>
<td>
How established is the Data Board and overall Governance of the Data Strategy?
</td>
<td>
Under study but no plan confirmed to put in place a formal Data Governance
</td>
<td>
Data Governance board(s) are scheduled irregularly (e.g. not more than twice a year) and with limited scope
</td>
<td>
A Data Board is in place, scheduled with a constant frequency, ExCom member(s) participate when relevant
</td>
<td>
A Data Board and Governance model has been formally defined, with constant frequency and participation of business representatives, and ExCom member(s) or direct representatives
</td>
<td>
All decisions around data are taken through the Data Governance model in place, empowered and legitimate vis-à-vis the ExCom and the entire organization
</td>
</tr>
<tr>
<td>
What is the impact of the Data Board?
</td>
<td>
No data board in place
</td>
<td>
No major impact - so far it is an information sharing board
</td>
<td>
Medium impact - Board meant for consultation and some decisions
</td>
<td>
Significant - validates the data strategy and decides to launch/stop data related initiatives
</td>
<td>
Strategic - guides the data initiatives to optimize value and innovation outcomes in the medium to long-term
</td>
</tr>
<tr>
<td>
To what extent does the Data Board monitor the use case portfolio execution and pipeline, as well as tracking the costs &amp; benefits?
</td>
<td>
No data board in place
</td>
<td>
Upon Request
</td>
<td>
Systematic / on selected major projects
</td>
<td>
Systematic/ for all major projects across the business lines, with involvement of Finance
</td>
<td>
Systematic/full scope/over the full lifecycle of projects (pre, during and after delivery), including transversal foundations
</td>
</tr>
<tr>
<td>
To what extent does the Data Board take decisions regarding Data Management activities (data usage, quality, availability, …)?
</td>
<td>
No data board in place
</td>
<td>
Upon Request
</td>
<td>
Systematic/partial scope on a few priority areas
</td>
<td>
Systematic/full scope of the data strategy (use cases and foundations) and regularly shared with CEO
</td>
<td>
L4+wider sharing and regular discussion with data-affine community of stakeholders
</td>
</tr>
<tr>
<td>
To what extent does the Data Board take decisions regarding Data Protection?
</td>
<td>
No data board in place
</td>
<td>
Upon Request
</td>
<td>
Systematic/partial scope on a few priority areas
</td>
<td>
Systematic/full scope of the data strategy (use cases and foundations) and regularly shared with CEO
</td>
<td>
L4+wider sharing and regular discussion with data-affine community of stakeholders
</td>
</tr>
<tr>
<td>
To what extent does the Data Board take decisions regarding Management of Risk?
</td>
<td>
No data board in place
</td>
<td>
Upon Request
</td>
<td>
Systematic/partial scope on a few priority areas
</td>
<td>
Systematic/full scope of the data strategy (use cases and foundations) and regularly shared with CEO
</td>
<td>
L4+wider sharing and regular discussion with data-affine community of stakeholders
</td>
</tr>
<tr>
<td>
To what extent does the Data Board take decisions regarding Human Resources/Change Management?
</td>
<td>
No data board in place
</td>
<td>
Upon Request
</td>
<td>
Systematic/partial scope on a few priority areas
</td>
<td>
Systematic/full scope of the data strategy (use cases and foundations) and regularly shared with CEO
</td>
<td>
L4+wider sharing and regular discussion with data-affine community of stakeholders
</td>
</tr>
<tr>
<td colspan="6">
3.4. INVOLVE STAKEHOLDER TO DELIVER THE STRATEGY
</td>
</tr>
<tr>
<td>
To what extent is the delivery of the data strategy discussed with, and supported/sponsored by the business?
</td>
<td>
No interaction, no significant activity
</td>
<td>
Some discussions with business PnL owners take place, irregularly
</td>
<td>
Regular discussion with business owners, some are actively sponsoring data initiatives
</td>
<td>
Business owners sponsor major data activities as well as some foundational activities to support future data use cases in their perimeter
</td>
<td>
There is a wider consensus across the ExCom to sponsor major initiatives in terms of value creation, innovation, as well as building long-term foundations
</td>
</tr>
<tr>
<td>
To what extent is the CDO / data team involved in business and IT design decisions across the entity (in order to enable future data driven use cases and applications - “data by design”)?
</td>
<td>
No interaction, no significant activity
</td>
<td>
Some discussions take place when CDO / data team members become aware of relevant activities
</td>
<td>
Regular discussions take place in some identified areas where stakeholders agree that requirements for data-driven use cases should be considered right from the start
</td>
<td>
Guidelines and processes are established to ensure that data requirements are taken into account in all major and minor change processes (e.g. digital, client UX, product design)
</td>
<td>
CDO and data teams are actively approached by broader organization to advise on design decisions right from the start
</td>
</tr>
<tr>
<td>
To what extent are interactions with Business Units (including Marketing/Distribution) is efficient and effective, following well-defined operating models?
</td>
<td>
No interaction, no use cases
</td>
<td>
Discussion has been stablished with other Business Units, a pipe of joint initiative/usecases have been identified and some ad’hoc activities are in place
</td>
<td>
Shared agenda; joint initiatives and/or use cases have been identified, prioritized and under execution with some business units. BAU activities (regulation, control, data management, …) have been identified and performed Ad’Hoc
</td>
<td>
Co-Sponsorship on joint iniative; Use cases and BAU activities have been defined, prioritized, constantly updated, performed and reviewed according to an agreed operating model
</td>
<td>
All business units are acting as Sponsor; the CDO participates to their governance; Service Level Engagement are in place
</td>
</tr>
<tr>
<td>
To what extent are interactions with IT is efficient and effective, following well-defined operating models?
</td>
<td>
No interaction, no significant activity
</td>
<td>
Discussions take place, but methodology and process are mostly ad-hoc for each use case, projects are significantly delayed
</td>
<td>
Some structuring of operating models has taken place for priority interactions (e.g. data protection, finance), but alignments still cause significant delay of some initiatives
</td>
<td>
Interactions with key stakeholders across lifecycle of data initiatives follow established processes and methodologies; some projects are still delayed, some are quite efficient already
</td>
<td>
L4 + to the degree that they can be considered fast and efficient
</td>
</tr>
<tr>
<td>
To what extent are interactions with the other Departments (Risk&amp;Compliance, Finance, HR, etc.)is efficient and effective, following well-defined operating models?
</td>
<td>
No interaction, no use cases
</td>
<td>
Discussions take place, but methodology and process are mostly ad-hoc for each use case
</td>
<td>
Some structuring of operating models has taken place for priority interactions (e.g. data protection, finance), but alignments still cause significant delay of some initiatives
</td>
<td>
Interactions with key stakeholders across lifecycle of data initiatives follow established processes and methodologies; some projects are still delayed, some are quite efficient already
</td>
<td>
L4 + to the degree that they can be considered fast and efficient
</td>
</tr>
<tr>
<td colspan="6">
3.5. SHARE, CO-BUILD AND LEVERAGE CAPABILITIES ACROSS ENTITIES
</td>
</tr>
<tr>
<td>
To what extent do you leverage and co-build Expertise &amp; Assets from other entities and/or from the Group?
</td>
<td>
Not considered
</td>
<td>
Currently considered, part of global communities
</td>
<td>
Regular contact with experts from other entities; local re-use of another entity/group Asset
</td>
<td>
Recognized leader within the Data Communities, providing knowledge, co-building new capabilities with others, re-using what others do, in an open source spirit
</td>
<td>
L4 + to the degree that it can be considered a significant add-on to local data-driven value creation
</td>
</tr>
<tr>
<td>
To what extent do/will you share Expertise &amp; Assets with other entities?
</td>
<td>
Not considered
</td>
<td>
Currently considered, part of global communities
</td>
<td>
Regular contacts of our experts with other entities; local re-use of our local asset by others
</td>
<td>
Recognized contributor, (co-)developed assets are generating value in other entities
</td>
<td>
L4 + to the degree that it can be considered a significant add-on to the data-driven value creation of others
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="manage-data-as-an-asset">4. Manage data as an asset</h3>
<div class="row">
<table>
<thead>
<tr>
<th width="25%">
Dimension/sections
</th>
<th width="15%">
L1 - No/Does not exist
</th>
<th width="15%">
L2 - Initial
</th>
<th width="15%">
L3 - Ad hoc
</th>
<th width="15%">
L4 - Managed
</th>
<th width="15%">
L5 - Institutionalized
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">
4.1. IMPLEMENT A DATA MANAGEMENT OFFICE
</td>
</tr>
<tr>
<td>
What is the level of implementation of the local Data Management Office (DMO)?
</td>
<td>
The DMO is not implemented
</td>
<td>
Somme activities of data management are done upon request
</td>
<td>
Project mode, ramping up
</td>
<td>
In place, recognized as bringing value
</td>
<td>
Full scope of target data under monitoring in BAU mode
</td>
</tr>
<tr>
<td colspan="6">
4.2. ENFORCE DATA POLICIES AND AWARENESS
</td>
</tr>
<tr>
<td>
How advanced is your data policy?
</td>
<td>
No plan to draft a data policy
</td>
<td>
Data policy is defined
</td>
<td>
Data policy is defined and applied, some processes are defined but no control
</td>
<td>
All processes are defined and some are under control to ensure data policy is applied
</td>
<td>
General governance is in place to apply and control the data policy
</td>
</tr>
<tr>
<td>
How advanced is your data privacy policy (internal and external)? (data privacy policy should enclose all the process that deals with data privacy, data usage in use cases, specific clause to add to the data contract, data board where the review is done…)
</td>
<td>
No plan to draft a data privacy policy
</td>
<td>
Data privacy policy is defined
</td>
<td>
Data privacy policy is defined and applied, Some processes are defined but no control
</td>
<td>
All processes are defined and some are under control to ensure data privacy policy is applied
</td>
<td>
General privacy governance is in place to apply and control the data privacy policy
</td>
</tr>
<tr>
<td>
To what extend are your employees aware of the two data policies of above?
</td>
<td>
No policies are defined
</td>
<td>
Top management is aware of the data policies
</td>
<td>
Some managers are aware of the data policies and apply them
</td>
<td>
Any employee knows the data policies and the governance bodies to make them applied
</td>
<td>
Internals and externals know and apply the data policies
</td>
</tr>
<tr>
<td colspan="6">
4.3. LEVERAGE DATA OWNERS AND STEWARDS
</td>
</tr>
<tr>
<td>
To what extend Business Data Owners contribute to the data management activities?
</td>
<td>
People have not been assigned to the role
</td>
<td>
The people has been just nominated and they understand and agree about their activities
</td>
<td>
They are in place - Acting upon request
</td>
<td>
BAU mode, they’re focusing on most Business Critical Data and able to give Business Quality Rules on those data
</td>
<td>
They handle full scope of Data of their domain
</td>
</tr>
<tr>
<td>
To what extend Data Stewards contribute to the data management activities?
</td>
<td>
People have not been assigned to the role
</td>
<td>
The people has been just nominated and they understand and agree about their activities
</td>
<td>
They are in place - Acting upon request
</td>
<td>
BAU mode, they’re focusing on most business Critical Data for data management quality and updating the data documentation
</td>
<td>
They handle full scope of Data of their domain (data documentation, data quality…)
</td>
</tr>
<tr>
<td colspan="6">
4.4. MANAGE DATA DOCUMENTATION
</td>
</tr>
<tr>
<td>
What is the level of maturity of your business data documentation (business glossary and business processes)?
</td>
<td>
The business documentation is not up-to-date and not easily accessible
</td>
<td>
Some business documentations are available but not updated
</td>
<td>
Some business documentations are available, frequently updated
</td>
<td>
Most of the business documentations are available, frequently updated and mastered by business owners/stewards
</td>
<td>
Business documentations are available, frequently updated and mastered by business owners/steward for all lines of businesses
</td>
</tr>
<tr>
<td>
To what extent are data dictionnaries available?
</td>
<td>
The data dictionnaries are not formalized and/or not accessible
</td>
<td>
Some scattered documentation linking technical meta-data to business terms exists but it is not easily accessible
</td>
<td>
They are implemented for a partial scope of data, with automatic technical metadata collection from data sources and updated links with business glossary by stewards and owners. The dictionnaries are commonly used to understand a data source.
</td>
<td>
They cover a partial scope of data and are updated regularly, automated technical metadata collection from main data sources. These data dictionnaries are used by all data stakeholders.
</td>
<td>
Technical metadata collection is completly automated for all business domains, links with business glossary is regularly updated.
</td>
</tr>
<tr>
<td>
To what extent is data lineage documented?
</td>
<td>
The data lineage is not documented and/or not accessible
</td>
<td>
Some data flows between IT applications containing the data are documented. But it is not easily accessible.
</td>
<td>
Some data lineage is well documented and it can be provided but on a limited scope.
</td>
<td>
Technical and functional lineages are in place for business critical data elements and major use cases.
</td>
<td>
Technical and functional lineages are linked to the data processing activities and business processes
</td>
</tr>
<tr>
<td>
To what extent is your Enterprise Data Model available as a reference for building applications (BI, analytics, API, etc.)?
</td>
<td>
No enterprise data model available
</td>
<td>
An enterprise data model exists but on limited number of subject areas
</td>
<td>
An enterprise data model exists for main business subject areas and is used as a reference for some projects
</td>
<td>
An enterprise data model covers the main business subject areas, is known and used by most projects, continuous improvement
</td>
<td>
An enterprise data model covers all the business subject areas, is used, continuous feedback loop and awareness
</td>
</tr>
<tr>
<td colspan="6">
4.5. TAKE CARE OF DATA QUALITY
</td>
</tr>
<tr>
<td>
To what extent do you measure the profitability of data quality management? (cost of non-quality)
</td>
<td>
No enterprise data model available
</td>
<td>
An enterprise data model exists but on limited number of subject areas
</td>
<td>
An enterprise data model exists for main business subject areas and is used as a reference for some projects
</td>
<td>
An enterprise data model covers the main business subject areas, is known and used by most projects, continuous improvement
</td>
<td>
An enterprise data model covers all the business subject areas, is used, continuous feedback loop and awareness
</td>
</tr>
<tr>
<td>
What is the level of maturity of your processes to manage data quality?
</td>
<td>
No measures are available
</td>
<td>
Some figures were produced for a specific project
</td>
<td>
Ad hoc evaluation
</td>
<td>
Systematic evaluation with some measures of benefits &amp; costs. All business rules implemented on critical data elements
</td>
<td>
Systematic measurement of benefits &amp; costs
</td>
</tr>
<tr>
<td>
What is the level of maturity of your processes to manage data lifecycle (retention rules)?
</td>
<td>
No process in place
</td>
<td>
Reaction mode only, registry of data quality issues with impact analysis and recommandations. No defined business rules
</td>
<td>
Data quality issues are assessed and prioritize, the biggest issues are remediated. Business rules are set for most of the critical data elements
</td>
<td>
Processes are in place, data quality is assessed, monitored and remediation plans are followed. All critical data are under control associated to business rules
</td>
<td>
Processes are optimized, defects are tracked, continuous and proactive data quality improvement. Business rules applied automatically on critical data elements
</td>
</tr>
<tr>
<td colspan="6">
4.6. FOCUS ON CRITICAL DATA ELEMENTS
</td>
</tr>
<tr>
<td>
Have you identified the critical data elements to deliver use cases, run operations and control risks?
</td>
<td>
No critical data identified and no plan to do it
</td>
<td>
Some elements have been identified as critical for running the current use cases portfolio, operations and control some risks
</td>
<td>
Critical data elements have been identified for current use cases portfolio, operations and risk based on agreed definition of critical
</td>
<td>
A process is defined and implemented for identifying the critical data elements. They are identified for the most valuable areas in order to run data use cases, operations and risks
</td>
<td>
Critical data elements are known across the company, the identification of the critical elements is part of the data projects lifecycle
</td>
</tr>
<tr>
<td>
To what extent are these critical data elements available?
</td>
<td>
No elements are identified
</td>
<td>
Elements can be provided on demand
</td>
<td>
Most of the elements are provided as a service with its respective documentation
</td>
<td>
All critical data elements are provided as a service. A repository of the documentation of critical data elements is available
</td>
<td>
A repository of critical data elements is available and constantly updated in function of the data environnment evolution
</td>
</tr>
<tr>
<td colspan="6">
4.7. LEVERAGE EXTERNAL DATA SERVICES
</td>
</tr>
<tr>
<td>
To what extent do you leverage external data services to run the use cases in your portfolio/roadmap?
</td>
<td>
Under study
</td>
<td>
Some external data is used
</td>
<td>
External data strategy executed for some business use cases
</td>
<td>
External data strategy executed and reviewed in Data Board
</td>
<td>
External data used as a competitive advantage
</td>
</tr>
<tr>
<td colspan="6">
4.8. MANAGE MASTER/REFERENCE DATA
</td>
</tr>
<tr>
<td>
What is the level of maturity of Customer Master Data Management?
</td>
<td>
Not planned or planned to be identified in the next 6 months
</td>
<td>
Scope of the master data and relation with other data are identified
</td>
<td>
There is a single point of truth but on a small scope of attributes, interfaces (contracts) are defined with master data producers and master data consumers
</td>
<td>
Operational processes are in place including data stewardship and issues remediation, master data is complete, accurate and consistent across applications
</td>
<td>
Master data lifecycle management from creation to deletion with changes impact analysis, versioning and data movment monitoring
</td>
</tr>
<tr>
<td>
What is the level of maturity of “Business Partners” (providers, distributors, …) Master Data Management?
</td>
<td>
Not planned or planned to be identified in the next 6 months
</td>
<td>
Scope of the master data and relation with other data are identified
</td>
<td>
There is a single point of truth but on a small scope of attributes, interfaces (contracts) are defined with master data producers and master data consumers
</td>
<td>
Operational processes are in place including data stewardship and issues remediation, master data is complete, accurate and consistent across applications
</td>
<td>
Master data lifecycle management from creation to deletion with changes impact analysis, versioning and data movment monitoring
</td>
</tr>
<tr>
<td>
What is the level of maturity of your Products/Services Master Data Management?
</td>
<td>
Not planned or planned to be identified in the next 6 months
</td>
<td>
Scope of the master data and relation with other data are identified
</td>
<td>
There is a single point of truth but on a small scope of attributes, interfaces (contracts) are defined with master data producers and master data consumers
</td>
<td>
Operational processes are in place including data stewardship and issues remediation, master data is complete, accurate and consistent across applications
</td>
<td>
Master data lifecycle management from creation to deletion with changes impact analysis, versioning and data movment monitoring
</td>
</tr>
<tr>
<td>
To what extent do you leverage standardized Reference Data (internal and external)?
</td>
<td>
Not planned or planned to be identified in the next 6 months
</td>
<td>
Scope of the reference data and relation with other data are identified
</td>
<td>
There is a single point of truth but on a small scope of attributes, interfaces (contracts) are defined with reference data producers and reference data consumers
</td>
<td>
Operational processes are in place including data stewardship and issues remediation, reference data is complete, accurate and consistent across applications
</td>
<td>
Reference data lifecycle management from creation to deletion with changes impact analysis, versioning and data movment monitoring
</td>
</tr>
<tr>
<td colspan="6">
4.9. MANAGE DATA ACCESS
</td>
</tr>
<tr>
<td>
To what extent are data access and data usage monitored?
</td>
<td>
Access can be granted without any validation
</td>
<td>
There is a process for access management but no control/audit
</td>
<td>
Access rights and data usage reports on a limited scope
</td>
<td>
Access rights and data usage reports for all critical data elements
</td>
<td>
Proactive access rights management, regular reviews on compliance and security usage
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="empower-people-and-the-broader-organization-to-deliver">5. Empower People, and the broader Organization, to Deliver</h3>
<div class="row">
<table>
<thead>
<tr>
<th width="25%">
Dimension/sections
</th>
<th width="15%">
L1 - No/Does not exist
</th>
<th width="15%">
L2 - Initial
</th>
<th width="15%">
L3 - Ad hoc
</th>
<th width="15%">
L4 - Managed
</th>
<th width="15%">
L5 - Institutionalized
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">
5.1. LEVERAGE DATA SKILLS / CURRENT STATUS OF HR
</td>
</tr>
<tr>
<td>
To what extent do you have the required people with Data Science skills to deliver the use cases in the portfolio?
</td>
<td>
Some projects stopped/not starting due to lack of resources
</td>
<td>
Striving for this year
</td>
<td>
Hiring and upskilling are done on a case by case basis
</td>
<td>
Needs are covered for the next 12 months
</td>
<td>
Needs are covered for the upcoming years within a plan
</td>
</tr>
<tr>
<td>
To what extent do you have the required people with Data Engineering skills to deliver the use cases and IT foundations?
</td>
<td>
Some projects stopped/not starting due to lack of resources
</td>
<td>
Striving for this year
</td>
<td>
Hiring and upskilling are done on a case by case basis
</td>
<td>
Needs are covered for the next 12 months
</td>
<td>
Needs are covered for the upcoming years within a plan
</td>
</tr>
<tr>
<td>
To what extent do you have the required people with Data Architecture skills (to fulfill the needs for defining, supporting and governing the Information Architecture required for both use cases and foundations)?
</td>
<td>
Some projects stopped/not starting due to lack of resources
</td>
<td>
Striving for this year
</td>
<td>
Hiring and upskilling are done on a case by case basis
</td>
<td>
Needs are covered for the next 12 months
</td>
<td>
Needs are covered for the upcoming years within a plan
</td>
</tr>
<tr>
<td>
To what extent do you have Business Transformers/Translators (connecting the dots between Business, Data and IT) to deliver data driven use cases in the portfolio
</td>
<td>
Some projects stopped/not starting due to lack of resources
</td>
<td>
Striving for this year
</td>
<td>
Hiring and upskilling are done on a case by case basis
</td>
<td>
Needs are covered for the next 12 months
</td>
<td>
Needs are covered for the upcoming years within a plan
</td>
</tr>
<tr>
<td colspan="6">
5.2. RECRUIT, DEVELOP AND RETAIN DATA TALENT
</td>
</tr>
<tr>
<td>
Recruit: To what extent is your sourcing strategy of data experts defined, implemented and monitored, as well as reflected in the rules and procedures of the local HR function?
</td>
<td>
Local HR involved only in the recruitment process
</td>
<td>
Skill requirements per profile are clear
</td>
<td>
A sourcing strategy defined and monitored with local HR on a limited scope of key profiles (for instance data scientist) including : 1) a skill’s baseline at the entity level 2) a pool of data expert’s skills at the Group level to meet the entities needs (internal &amp; external)
</td>
<td>
A sourcing strategy defined and monitored with the local HR per key profiles. Including internal (group, …) and external sourcing. Taking into account the characteristics of the entity (market competitors, …)
</td>
<td>
L4 + definition of a consistent target of key indicators related to recruitment. Information sessions, conference participations and extra activities (e.g. hackathons) at target universities
</td>
</tr>
<tr>
<td>
Develop: To what extent is your education (training and development) approach of data experts defined, implemented and monitored, as well as reflected in the rules and procedures of the local HR function?
</td>
<td>
No local up/reskilling approach. Only group training services (Coursera) are used.
</td>
<td>
Some initiatives are on going with local HR, mainly covering data specialists (local data scientist community, local training session, …)
</td>
<td>
A training plan is implemented and monitored, covering priority parts of the the entity population.
</td>
<td>
A “Data track” implemented and monitored with the local HR to identify the training needs and define an appropriate training plan covering the different populations at the entity level. The plan relies on different levers (training, data expert communities, peer to peer exchange, …) provided both by the Group and locally
</td>
<td>
L4 + a regular assessment of data skills is held. definition of a consistent target of key indicators related development/training. People are offered the opportunity for additional higher education (PhD, graduate school) supported by AXA
</td>
</tr>
<tr>
<td>
Retain: To what extent is your retention approach of data experts defined, implemented and monitored, as well as reflected in the rules and procedures of the local HR function?
</td>
<td>
No retention approach. Local HR involved only in the recruitment process
</td>
<td>
Retention requirements are clear. Some levers/actions are already implemented
</td>
<td>
A retention approach defined and monitored by the local HR on a limited scope of key profiles (eg. data scientist). This mainly involves putting the key people in charge with use cases they appreciate
</td>
<td>
A retention approach defined and monitored by the local HR for the key profiles. Key people are put on attractive projects, and get promoted (within the existing HR framework) as much as is feasible
</td>
<td>
L4 + definition of a consistent target of key indicators related retention establishing a career journey that does not necessarily involve HR responsibility, but technical/product responsibility, while still enabling higher, competitive paygrades. This requires a change in the HR framework
</td>
</tr>
<tr>
<td colspan="6">
5.3. MANAGE CHANGE ACROSS THE ORGANIZATION AND EMPOWER THE COMMUNITY
</td>
</tr>
<tr>
<td>
To what extent is the community of data-affine employees, managers and senior executives and empowered to contribute to the data strategy?
</td>
<td>
No survey, no actions
</td>
<td>
There exists a platform / forum to communicate ideas and proposals for new data-driven projects and products; some members of the data team and business stakeholders contribute to the community
</td>
<td>
L2 + existing procedure to put ideas into action; a community manager is spending significant time to keep the community active
</td>
<td>
L3 + for these ideas special budgets and resources are available (e.g. dedicated time for business stakeholders to contribute as ambassadors for change)
</td>
<td>
L4 + regular assessment of progress and success of these projects
</td>
</tr>
<tr>
<td>
To what extent a change plan is described and deployed to implement Data Culture at all level of your organization?
</td>
<td>
A Communication plan has been described and deployed on all employees
</td>
<td>
An Engagement plan including Smart° Data Awareness has been described and deployed on all employees
</td>
<td>
L2 + A Development plan including Learning &amp; Development initiatives has been deployed on all employees
</td>
<td>
L3 + An Improvement plan, prioritized and segmented by key targets, has been described and deployed on all employees
</td>
<td>
The overall Data Culture Transformation Framework is described and is deployed. Data Culture transformation is monitored
</td>
</tr>
</tbody>
</table>
</div>
<h3 id="deliver-and-operate-data-platforms">6. Deliver and operate data platforms</h3>
<div class="row">
<table>
<thead>
<tr>
<th width="25%">
Dimension/sections
</th>
<th width="15%">
L1 - No/Does not exist
</th>
<th width="15%">
L2 - Initial
</th>
<th width="15%">
L3 - Ad hoc
</th>
<th width="15%">
L4 - Managed
</th>
<th width="15%">
L5 - Institutionalized
</th>
</tr>
</thead>
<tbody>
<tr>
<td colspan="6">
6.1. DEFINE A DATA PLATFORM STRATEGY
</td>
</tr>
<tr>
<td>
Do you have a platform strategy and roadmap (requirements management and roadmap, platforms and application portfolio management, service management, culture and innovation, etc.) for Data Platforms (BI/Big Data, Meta/Reference/Master Data, Data Quality, Integration/Exchange/API)?
</td>
<td>
No strategy in place
</td>
<td>
Draft version
</td>
<td>
Requirements are defined and managed, mid term 2-3 years roadmap, with focus on some business domains
</td>
<td>
Mid term 2-3 years roadmap, aligned with the data strategy and its roadmap
</td>
<td>
5+ year vision, encompassing all business domains
</td>
</tr>
<tr>
<td>
To what extent do you apply the agile methodologies?
</td>
<td>
No agile methodologies in place
</td>
<td>
Teams start to use knowledge sharing, agile tools and practices
</td>
<td>
Most of the project portfolio is agile, the roles and responsibilities are clear, disciplined and repeatable procedures are executed
</td>
<td>
Successful use of agile at scale, measurements systems in place to track business value realization, agile habits at a high maturity across the entity
</td>
<td>
Lean and agile are part of the entity culture, continuous organizational learning and optimization of work process
</td>
</tr>
<tr>
<td>
To what extent do you manage IT operational risks (security, compliance, supportability, business continuity plan, disaster recovery, etc.)?
</td>
<td>
No governance processes, no business impact assessments
</td>
<td>
Some operational risks are identified and business impact assessments are done for new projects only
</td>
<td>
Assessments exists for all business critical applications with mitigation plans
</td>
<td>
Regular plan and budget to review the complete application portfolio aligned with the business, some testing in production are undertaken
</td>
<td>
Regular testing in production (security pentests, disaster recovery tests, etc.)
</td>
</tr>
<tr>
<td colspan="6" class="info">
6.2. DELIVER AND OPERATE INTEGRATION SERVICES
</td>
</tr>
<tr>
<td>
What are your integration services capabilities to collect and share data?
</td>
<td>
Manual (no tool)
</td>
<td>
Specific tools for batch file extractions, no monitoring console
</td>
<td>
ETL services with connectors and monitoring, no real-time data integration services
</td>
<td>
Real-time capabliities on critical data elements: change data capture and/or messaging and/or APIs
</td>
<td>
Data can be easily made available through an API, data integration service levels are continuously monitored and improved
</td>
</tr>
<tr>
<td>
To what extent have you documented the services that allow registration, management, and business usage monitoring of data integration services?
</td>
<td>
Manual (no tool)
</td>
<td>
Some repository/registry exist, discrepancies depending on the integration solution
</td>
<td>
All integration solutions include a repository/registry that allows governance of integration services
</td>
<td>
Central registry/catalog of integration services, easily accessible (discoverability, documentation)
</td>
<td>
L4+Integration usage (consumption) is monitored and used to optimize business value of integration services
</td>
</tr>
<tr>
<td>
To what extent do your integration platforms work as Business As Usual? (incident management, access management, problem management, change management)
</td>
<td>
Chaotic and unpredictable support
</td>
<td>
Ticketing system to manage technical incidents
</td>
<td>
Incidents and problems resolution process, no service catalog
</td>
<td>
Service catalog, BAU processes and service levels are defined
</td>
<td>
Monitoring and following of service levels with periodic reviews and continuous improvement
</td>
</tr>
<tr>
<td colspan="6">
6.3. DELIVER AND OPERATE BI &amp; ANALYTICS SERVICES
</td>
</tr>
<tr>
<td>
To what extent do you provide services to store and deliver data for use cases?
</td>
<td>
Mostly legacy data, raw data history is not kept
</td>
<td>
Raw data is available but not organized and not optimized, lack of metadata
</td>
<td>
Optimized storage of raw data with management of data history and classification, raw data is used by multiple use cases
</td>
<td>
Optimized storage of raw data, multi-sources consolidation of business keys, clear segregation between technical and business data processing
</td>
<td>
Adapt to data evolutions without complex reengineering, repeatable and automated data engineering process, fault-tolerance, scalablity
</td>
</tr>
<tr>
<td>
To what extent do you provide services for information delivery?
</td>
<td>
End-user computing in Access/Excel
</td>
<td>
Operational dashboards provided by operational applications, some information marts and dashboards on a limited business scope
</td>
<td>
Enterprise BI (dashboarding, alerting, etc) covering multiple business areas and supporting a large number of users
</td>
<td>
Advanced Enterprise BI with usage statistics + response time performance under SLA + Self-Service BI + information write-back capability
</td>
<td>
Advanced BI experience: responsive design, Q&amp;A, integration with operational and mobile applications, social BI, etc.
</td>
</tr>
<tr>
<td>
To what extent is the workplace for data scientists and actuaries adapted to their needs?
</td>
<td>
End-user computing in Access/Excel
</td>
<td>
Data science workbench can be provided on demand, no collaboration capability
</td>
<td>
Data science workbench can be provided, access to a laboratory environment to test &amp; learn new models
</td>
<td>
Workplace based on profile giving all necessary tools and possibility to add new features on-demand, possible to run the models on a cluster on demand
</td>
<td>
Collaborative workplace and autonomy for data science in a secured environment, scalable and without having to move data in and out, easy to deploy the models in production
</td>
</tr>
<tr>
<td>
To what extent is the workplace for data engineers adapted to their needs?
</td>
<td>
Standalone development
</td>
<td>
Some basic data engineering tools can be provided on demand, no collaboration capability
</td>
<td>
Data engineering development environment can be provided with access to a source code repository
</td>
<td>
Complete workplace based on profile giving all necessary tools for their work, source code repository and continuous integration environment
</td>
<td>
Collaborative workplace, continuous integration, testing and deployment
</td>
</tr>
<tr>
<td>
To what extent is the workplace for AI engineers adapted to their needs?
</td>
<td>
Standalone development
</td>
<td>
Dedicated environment can be provided on demand without any specific service for AI engineering
</td>
<td>
AI engineering environment can be provided, machine learning experiments tracking (code, data, configuration, results)
</td>
<td>
Registry of experiments and machine learning models accessible through APIs and with metadata management, seamless integration from CI/CD pipelines
</td>
<td>
Seamless integration between analytical system and digital 24/7 system, tools for orchestration, triggering ML model training and A/B testing
</td>
</tr>
<tr>
<td>
To what extend do you provide a service to manage the data lifecycle from creation to deletion?
</td>
<td>
No service to manage data lifecycle
</td>
<td>
File / Table level deletion on-demand
</td>
<td>
File / Table / Column level deletion specific development based on data retention rules
</td>
<td>
A service is available to automate execution of data lifecycle rules with logging and audit capability
</td>
<td>
A service is available with advanced anonymization/pseudnomyzation techniques
</td>
</tr>
<tr>
<td>
To what extent do your BI &amp; Analytics platforms work as Business As Usual? (incident management, access management, problem management, change management)
</td>
<td>
Chaotic and unpredictable support
</td>
<td>
Ticketing system to manage technical incidents
</td>
<td>
Incidents and problems resolution process, no service catalog
</td>
<td>
Service catalog, BAU processes and service levels are defined
</td>
<td>
Monitoring and following of service levels with periodic reviews and continuous improvement
</td>
</tr>
<tr>
<td colspan="6">
6.4. DELIVER AND OPERATE MASTER &amp; REFERENCE DATA MANAGEMENT SERVICES
</td>
</tr>
<tr>
<td>
To what extent do you provide services to manage Master Data and Reference Data?
</td>
<td>
No specific services to manage master data
</td>
<td>
Master data cleaning and deduplication services
</td>
<td>
Hierachy and relationships management, master data identity resolution, master data authoring
</td>
<td>
Master data management workflows, services are available through APIs, reporting and alerting on data integration and data quality issues
</td>
<td>
Master data are available as a service and can be integrated in operational processes, continuous monitoring, proactive alerting and resolution
</td>
</tr>
<tr>
<td>
To what extend do you provide a service to manage the data lifecycle from creation to deletion?
</td>
<td>
No service to manage data lifecycle
</td>
<td>
File / Table level deletion on-demand
</td>
<td>
File / Table / Column level deletion specific development based on data retention rules
</td>
<td>
A service is available to automate execution of data lifecycle rules with logging and audit capability
</td>
<td>
A service is available with advanced anonymization/pseudnomyzation techniques
</td>
</tr>
<tr>
<td>
To what extent your Master Data and Reference Data platforms work as Business As Usual? (incident management, access management, problem management, change management)
</td>
<td>
Chaotic and unpredictable support
</td>
<td>
Ticketing system to manage technical incidents
</td>
<td>
Incidents and problems resolution process, no service catalog
</td>
<td>
Service catalog, BAU processes and service levels are defined
</td>
<td>
Monitoring and following of service levels with periodic reviews and continuous improvement
</td>
</tr>
<tr>
<td colspan="6">
6.5. DELIVER AND OPERATE DATA QUALITY AND METADATA MANAGEMENT SERVICES
</td>
</tr>
<tr>
<td>
To what extent do you provide services to manage business and technical metadata?
</td>
<td>
No specific services to manage a business and technical metadata
</td>
<td>
Content management and authoring service
</td>
<td>
Specific services to manage business and technical metadata with roles and workflows for authoring
</td>
<td>
Centralized metadata repository to link business and technical metadata, metadata change tracking, APIs and portal to make them accessible
</td>
<td>
Advanced end-user experience to manage the data knowledge: facets search, graph. views, recommandation engine, extension to unstructured documents, etc.
</td>
</tr>
<tr>
<td>
To what extent do you provide services to integrate buiness and technical metadata with operational metadata (action logs, data quality profiles, etc.)
</td>
<td>
No access to operational metadata
</td>
<td>
Manual integration of operational metadata with business and technical metadata
</td>
<td>
Operational metadata are available and I can perfom ad-hoc analysis on large volumes of metadata
</td>
<td>
Operational metadata mart with reporting including business metadata and technical metadata dimensions
</td>
<td>
Anomalie detection n operational metadata and near real time alerting, what-if analysis, predictions based on operational metadat (peak hours, nb of queries scaling, …)
</td>
</tr>
<tr>
<td>
To what extent your Meta Data platforms work as Business As Usual? (incident management, access management, problem management, change management)
</td>
<td>
Chaotic and unpredictable support
</td>
<td>
Ticketing system to manage technical incidents
</td>
<td>
Incidents and problems resolution process, no service catalog
</td>
<td>
Service catalog, BAU processes and service levels are defined
</td>
<td>
Monitoring and following of service levels with periodic reviews and continuous improvement
</td>
</tr>
</tbody>
</table>
</div>
        </div>
		</div>
    </div>
            

<script>
/*
window.addEventListener('DOMContentLoaded', function() {
	document.documentElement.style.setProperty('--text-color', 'red');
});
*/
</script>

	<script>
        // function to set a given theme/color-scheme
        function setTheme(themeName) {
            localStorage.setItem('theme', themeName);
			if (themeName === 'theme-light') {
				document.documentElement.style.setProperty('--background-color', 'white');
				document.documentElement.style.setProperty('--caption-color', 'white');
				document.documentElement.style.setProperty('--text-color', 'black');
				document.documentElement.style.setProperty('--content-color', '#1C242B');
			}
			else {
				document.documentElement.style.setProperty('--background-color', 'black');
				document.documentElement.style.setProperty('--caption-color', '#091F2C');
				document.documentElement.style.setProperty('--text-color', '#C7D1DB');
				document.documentElement.style.setProperty('--content-color', '#C7D1DB');
			}
        }

        // immediately invoked function to set the theme on initial load
        (function () {
            if (localStorage.getItem('theme') === 'theme-dark') {
                setTheme('theme-dark');
            }
			else if (localStorage.getItem('theme') === 'theme-light') {
                setTheme('theme-light');
            }
			else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
				setTheme('theme-dark');
			}
			else if (window.matchMedia && window.matchMedia('(prefers-color-scheme: ligth)').matches) {
				setTheme('theme-ligth');
			}
			else {
				// default theme is dark
				setTheme('theme-dark');
			}
        })();
    </script>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <!--<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>-->
	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="https://maxcdn.bootstrapcdn.com/js/ie10-viewport-bug-workaround.js"></script>
    <script>        
        /* ajust the height when click the toc
           the code is from https://github.com/twbs/bootstrap/issues/1768
        */
        var shiftWindow = function() { scrollBy(0, -50) };
        window.addEventListener("hashchange", shiftWindow);
        function load() { if (window.location.hash) shiftWindow(); }
        
        /* add Bootstrap styles to tables */
		var tables = document.getElementsByTagName("table");
        for(var i = 0; i < tables.length; ++i){
            tables[i].className += "table table-bordered table-hover";
        }
    </script>

  </body>
</html>